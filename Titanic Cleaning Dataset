import pandas as pd
import numpy as np

#load the dataset
df = pd.read_csv("Titanic-Dataset.csv")
print(df.head())

#Data exploration and inspection
print(df.duplicated())

#heck the data information
print(df.info())

#Check the Categorical and Numerical Columns.
cat_col = [col for col in df.columns if df[col].dtype == 'object']
print('Categorical columns :',cat_col)

num_col = [col for col in df.columns if df[col].dtype != "object"]
print('Numerical columns :',num_col)

#Check the total number of Unique Values in the Categorical Columns
print(df[cat_col].nunique())

'''Now we have to make a decision according to the subject of analysis which factor is important for our discussion.
As we know our machines don’t understand the text data. So we have to either drop or convert the categorical column values into numerical types. Here we are dropping the Name columns because the Name will be always unique and it hasn’t a great influence on target variables. For the ticket, 
Let’s first print the 50 unique tickets.'''

print(df['Ticket'].unique()[:50])
df1 = df.drop(columns=['Name','Ticket'])
print(df1.shape)

#Handling Missing Data
df2 = df1.drop(columns='Cabin')
df2.dropna(subset=['Embarked'], axis=0, inplace=True)
print(df2.shape)

# Mean imputation
df3 = df2.fillna(df2.Age.mean())
# Let's check the null values again
print(df3.isnull().sum())

import matplotlib.pyplot as plt

plt.boxplot(df3['Age'], vert=False)
plt.ylabel('Variable')
plt.xlabel('Age')
plt.title('Box Plot')
plt.show()

# calculate summary statistics
mean = df3['Age'].mean()
std  = df3['Age'].std()

# Calculate the lower and upper bounds
lower_bound = mean - std*2
upper_bound = mean + std*2

print('Lower Bound :',lower_bound)
print('Upper Bound :',upper_bound)

# Drop the outliers
df4 = df3[(df3['Age'] >= lower_bound) 
                & (df3['Age'] <= upper_bound)]

X = df3[['Pclass','Sex','Age', 'SibSp','Parch','Fare','Embarked']]
Y = df3['Survived']

from sklearn.preprocessing import MinMaxScaler

# initialising the MinMaxScaler
scaler = MinMaxScaler(feature_range=(0, 1))

# Numerical columns
num_col_ = [col for col in X.columns if X[col].dtype != 'object']
x1 = X
# learning the statistical parameters for each of the data and transforming
x1[num_col_] = scaler.fit_transform(x1[num_col_])
x1.head()
